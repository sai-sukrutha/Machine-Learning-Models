{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pass the percentage of data you need for test like 20 % \n",
    "def train_split(df,test_per):\n",
    "    indices=df.index.tolist()\n",
    "    test_size=round(len(df)*(test_per/100))\n",
    "    random.seed(0)\n",
    "    test_indices=random.sample(population=indices,k=test_size)\n",
    "    valid_df=df.loc[test_indices]\n",
    "    train_df=df.drop(test_indices)\n",
    "    return train_df,valid_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def sigmoid(x):\n",
    "#     return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(X):\n",
    "    sigmoid_ans=np.zeros(X.shape,dtype=np.float128)\n",
    "    for i in range(0,len(X)):\n",
    "        x=X[i]\n",
    "        exp_part=np.exp(-x)\n",
    "        sigmoid_ans[i]=1/(1+exp_part)\n",
    "\n",
    "    return sigmoid_ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(X):\n",
    "    no_rows,no_labels=X.shape\n",
    "    soft_array=np.zeros(X.shape)\n",
    "    for j in range(no_rows):\n",
    "        x=X[j]\n",
    "        sum=0\n",
    "        for i in range(len(x)):\n",
    "            sum+=np.exp(x[i])\n",
    "        if(sum != 0):\n",
    "            for i in range(len(x)):\n",
    "                soft_array[j][i]=np.exp(x[i])/sum\n",
    "        else:\n",
    "            print(\"Error:Sum is zero\")\n",
    "        \n",
    "    return soft_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Derivatives of Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def derivative_sigmoid(x):\n",
    "    return sigmoid(x) * (1 - sigmoid(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE_error(actual_Y,predicted_Y):\n",
    "    m=len(actual_Y)\n",
    "    MSE=0\n",
    "    for i in range(0,len(actual_Y)):\n",
    "        actual=actual_Y[i]\n",
    "        predicted=predicted_Y[i]\n",
    "        MSE+=pow((actual-predicted),2)  \n",
    "    MSE/=m\n",
    "\n",
    "    return MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(actual_Y,predicted_Y):\n",
    "    E=0\n",
    "    for i in range(len(actual_Y)):\n",
    "        if(predicted_Y[i] == 0):\n",
    "            continue\n",
    "        E-=(actual_Y[i]*np.log2(predicted_Y[i]))\n",
    "    return E"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN(X,Y,label):\n",
    "    \n",
    "    #Initialize layers\n",
    "    no_samples,no_cols=X.shape\n",
    "    no_labels=10\n",
    "    \n",
    "    no_I=no_cols     #Input layer\n",
    "    no_O=no_labels  #Output layer\n",
    "    #print(\"Nodes in Input layer-\",no_I)\n",
    "    #print(\"Nodes in Output layer-\",no_O)\n",
    "    no_H=int(math.sqrt(no_I*no_O))  #Hidden layer-1 Hidden layer\n",
    "    #print(\"Nodes in Hiddden layer-\",no_H)\n",
    "    \n",
    "    #Initializing weights and bias\n",
    "    # W_H=np.random.uniform(size=(no_I,no_H))\n",
    "    # W_O=np.random.uniform(size=(no_H,no_O))\n",
    "    # B_H=np.random.uniform(size=(1,no_H))\n",
    "    # B_O=np.random.uniform(size=(1,no_O))\n",
    "    W_H=np.random.rand(no_I,no_H)\n",
    "    W_O=np.random.rand(no_H,no_O)\n",
    "    B_H=np.random.rand(1,no_H)\n",
    "    B_O=np.random.rand(1,no_O)\n",
    "    #print(\"Initial\")\n",
    "    #print(\"Weights-\",W_O,W_H)\n",
    "    #print(\"Biases-\",B_O,B_H)\n",
    "    \n",
    "    #One-hot encode Y\n",
    "    Y=one_hot_encode(Y,no_labels)\n",
    "\n",
    "    alpha=0.003\n",
    "    epoch=1000\n",
    "    error_cost=[]\n",
    "    \n",
    "    while(epoch > 0):\n",
    "        \n",
    "        #Forward Propagation\n",
    "        H_in=X.dot(W_H)+B_H\n",
    "        H_out=sigmoid(H_in)\n",
    "        O_in=H_out.dot(W_O)+B_O\n",
    "        #O_out=sigmoid(O_in)\n",
    "        O_out=softmax(O_in)\n",
    "        #print(\"O_out-\",O_out)\n",
    "        \n",
    "        #Backward Propagation\n",
    "        #Error=MSE_error(Y,O_out)\n",
    "        #Error=entropy(Y,O_out)\n",
    "        Error=Y-O_out\n",
    "        slope_O=derivative_sigmoid(O_out)\n",
    "        slope_H=derivative_sigmoid(H_out)\n",
    "        delta_O=Error*slope_O\n",
    "        Error_H=delta_O.dot(W_O.T)\n",
    "        delta_H=Error_H*slope_H\n",
    "        \n",
    "        #update weights and bias\n",
    "        W_O=W_O+alpha*(H_out.T.dot(delta_O))\n",
    "        W_H=W_H+alpha*(X.T.dot(delta_H))        \n",
    "        B_O+=np.sum(delta_O)*alpha\n",
    "        B_H+=np.sum(delta_H)*alpha\n",
    "        #print(W_O,W_H,B_O,B_H)\n",
    "        \n",
    "        if epoch % 200 == 0:\n",
    "            loss = np.sum(-Y*np.log(O_out))\n",
    "            print('Loss function value: ', loss)\n",
    "            error_cost.append(loss)\n",
    "        \n",
    "        epoch-=1\n",
    "    \n",
    "    #print(O_out)\n",
    "    #print(error_cost)\n",
    "    return O_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating X(data.T),Y arrays from df\n",
    "def to_arrays(df,label):\n",
    "    no_rows,no_cols=df.shape\n",
    "    header=list(df.columns)\n",
    "    data_array=np.ones((no_cols-1,no_rows))\n",
    "    for i in range(1,no_cols):             #Removing first col-label\n",
    "            x=df[header[i]].values\n",
    "            #data_array[i-1]=x\n",
    "            data_array[i-1]=mean_normalize(x)\n",
    "    X=data_array.T\n",
    "\n",
    "    #Y (output) array\n",
    "    Y=np.array(df[label].values)  \n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_normalize(x):\n",
    "    x_new=np.zeros(len(x))\n",
    "    mean=np.mean(x)\n",
    "    std=np.std(x)\n",
    "    for i in range(0,len(x)):\n",
    "        if( int(mean) == 0):\n",
    "            #print(\"mean is zero\")\n",
    "            x_new[i]=x[i]\n",
    "        elif( int(std) == 0 ):\n",
    "            #print(\"std is zero\")\n",
    "            x_new[i]=(x[i]- int(mean))\n",
    "        else:\n",
    "            x_new[i]=(x[i]-mean)/std\n",
    "    return x_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(Y,no_labels):\n",
    "    encoded_Y=np.zeros((len(Y),no_labels))\n",
    "    for i in range(0,len(Y)):\n",
    "        encoded_Y[i,Y[i]]=1\n",
    "    return encoded_Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \n",
    "    #Loading the file\n",
    "    file=\"Apparel/apparel-trainval.csv\"\n",
    "    label='label'\n",
    "    df=pd.read_csv(file)\n",
    "   \n",
    "    #Train and Validation Split\n",
    "    #train_df,valid_df=train_split(df,20)\n",
    "    train_df=df\n",
    "    \n",
    "    #Training\n",
    "    train_X,train_Y=to_arrays(train_df,label)\n",
    "    \n",
    "    output=NN(train_X,train_Y,label)\n",
    "\n",
    "    #Writing to file\n",
    "    output_file=\"output_prediction.csv\"\n",
    "    f = open(output_file,\"w\")\n",
    "    no_rows,no_labels=output.shape\n",
    "    correct=0\n",
    "    for i in range(no_rows):\n",
    "        prediction=np.argmin(output[i])\n",
    "        actual=train_Y[i]\n",
    "        if(actual == prediction):\n",
    "            correct+=1\n",
    "        #print(prediction)\n",
    "        f.write(str(prediction))\n",
    "\n",
    "    accuracy=correct/no_rows\n",
    "    print(\"Accuracy-\",accuracy)\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss function value:  195558.97067047574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sukku/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: RuntimeWarning: overflow encountered in exp\n",
      "  \"\"\"\n",
      "/home/sukku/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:62: RuntimeWarning: divide by zero encountered in log\n",
      "/home/sukku/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:62: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss function value:  nan\n",
      "Loss function value:  nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sukku/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:8: RuntimeWarning: overflow encountered in exp\n",
      "  \n",
      "/home/sukku/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: overflow encountered in exp\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/home/sukku/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: invalid value encountered in longdouble_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
