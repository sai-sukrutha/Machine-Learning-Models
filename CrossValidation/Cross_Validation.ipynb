{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cost function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ridge Regularization\n",
    "def cost_function(X, Y, W ,lamda):\n",
    "    #Cost function J=(1/2m)*[(sum(pow(hypothesis(xi) - (yi)),2)) + (lamda*sum(pow(wi,2))) ]#hypothesis=X.T*W as X=data.T\n",
    "    m = len(Y)\n",
    "    reg_penalty=(lamda)*np.sum(np.square(W))\n",
    "    J=0\n",
    "    for i in range(0,m):\n",
    "        x=X[i]\n",
    "        y=Y[i]\n",
    "        hypothesis=x.dot(W)\n",
    "        J+=(pow(hypothesis-y,2))\n",
    "    J+=reg_penalty\n",
    "    J/=(2*m)\n",
    "    return J"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(X,Y,B,lamda,alpha,prev_cost):\n",
    "    #formula: Bj = Bj - alpha*(1/m)*((hypothesis(x)-y)*xj) - lamda/m*Bj\n",
    "    m=len(Y)\n",
    "    for j in range(0,len(B)):\n",
    "        sum=0\n",
    "        gradient=1\n",
    "        for i in range(0,m):\n",
    "            x=X[i]\n",
    "            y=Y[i]\n",
    "            hypothesis=x.dot(B)\n",
    "            sum+=(hypothesis-y)*x[j]\n",
    "        reg_penalty=lamda/m*B[j]\n",
    "        gradient=sum/m\n",
    "        #update Bj\n",
    "        if( j == 0):\n",
    "            B[j]-=(alpha*gradient)\n",
    "        else:\n",
    "            B[j]-=(alpha*gradient) + reg_penalty\n",
    "    cost=cost_function(X,Y,B,lamda)\n",
    "    #print(prev_cost,cost)\n",
    "    if(abs(prev_cost - cost) <  0.000001):\n",
    "        return B,cost\n",
    "    else:\n",
    "        B,cost=gradient_descent(X,Y,B,lamda,alpha,cost)\n",
    "    return B,cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x,B):\n",
    "    ans=x.dot(B)\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_error(X,Y,B):\n",
    "    actual_list=[]\n",
    "    predicted_list=[]\n",
    "    m=len(Y)\n",
    "    MSE=0\n",
    "    MAE=0\n",
    "    MPE=0\n",
    "    for i in range(0,len(X)):\n",
    "        actual=Y[i]\n",
    "        predicted=predict(X[i],B)\n",
    "        MSE+=pow((actual-predicted),2)\n",
    "        MAE+=abs(actual-predicted)\n",
    "        MPE+=MAE/actual*1    \n",
    "    MSE/=m\n",
    "    MAE/=m\n",
    "    MPE/=m\n",
    "    return MSE,MAE,MPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_MSE(X,Y,B):\n",
    "    m=len(Y)\n",
    "    MSE=0\n",
    "    for i in range(0,len(X)):\n",
    "        actual=Y[i]\n",
    "        predicted=predict(X[i],B)\n",
    "        MSE+=pow((actual-predicted),2)    \n",
    "    MSE/=m\n",
    "    return MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_MSE_loocv(x,y,B):\n",
    "    MSE=0\n",
    "    actual=y\n",
    "    predicted=predict(x,B)\n",
    "    MSE+=pow((actual-predicted),2)    \n",
    "    return MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_reg_error(train_X,train_Y,B,lamda,alpha,valid_X,valid_Y):\n",
    "    \n",
    "    init_J=cost_function(train_X,train_Y,B,lamda)\n",
    "    \n",
    "    B,final_J=gradient_descent(train_X,train_Y,B,lamda,alpha,init_J)\n",
    "    #print(\"Final_cost- \",final_J)\n",
    "    #print(B)\n",
    "    \n",
    "    MSE=cal_MSE(valid_X,valid_Y,B)\n",
    "    return MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfold_cross_val_split(df,k):\n",
    "    indices=df.index.tolist()\n",
    "    rows=df.shape[0]\n",
    "    if( rows % k != 0):\n",
    "        print(k,\" doesnot divide data correctly Data size-\",rows)\n",
    "        \n",
    "    fold_size= int(df.shape[0]/k)\n",
    "    folds_list=[]\n",
    "\n",
    "    for i in range(k-1):\n",
    "        indices=df.index.tolist()\n",
    "        random.seed(0)\n",
    "        random_indices=random.sample(population=indices,k=fold_size)\n",
    "        folds_list.append(df.loc[random_indices])\n",
    "        df=df.drop(random_indices)\n",
    "    folds_list.append(df)\n",
    "    \n",
    "    return folds_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_cross_val(folds_list,label,alpha,lamda):\n",
    "    k=len(folds_list)\n",
    "    no_coefficients=8\n",
    "    train_df=pd.DataFrame()\n",
    "    valid_df=pd.DataFrame()\n",
    "    error_list={}    #{error:B}\n",
    "    for i in range(k):\n",
    "        train_df=pd.DataFrame()\n",
    "        valid_df=pd.DataFrame()\n",
    "        for j in range(k):\n",
    "            if( j == i):\n",
    "                valid_df=folds_list[j]\n",
    "            else:\n",
    "                train_df=pd.concat([train_df, folds_list[j]])\n",
    "        train_X,train_Y=to_arrays(train_df,label)\n",
    "        valid_X,valid_Y=to_arrays(valid_df,label)\n",
    "        B = np.zeros(no_coefficients)\n",
    "        error=linear_reg_error(train_X,train_Y,B,lamda,alpha,valid_X,valid_Y)\n",
    "        error_list[error]=B.tolist()\n",
    "    return error_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_loocv(df,label,alpha,lamda):\n",
    "    k=len(df)\n",
    "    no_coefficients=8\n",
    "    train_df=pd.DataFrame()\n",
    "    valid_df=pd.DataFrame()\n",
    "    error_list={}    #{error:B}\n",
    "    for i in range(k):\n",
    "        train_df=pd.DataFrame()\n",
    "        valid_df=pd.DataFrame()\n",
    "        for j in range(k):\n",
    "            if( j == i):\n",
    "                valid_df=df.loc[i]\n",
    "                train_df=df.drop(i)\n",
    "        train_X,train_Y=to_arrays_loocv(train_df,label)\n",
    "        valid_X=valid_df[:8]\n",
    "        valid_Y=valid_df[8]\n",
    "        B = np.zeros(no_coefficients)\n",
    "        init_J=cost_function(train_X,train_Y,B,lamda)\n",
    "        B,final_J=gradient_descent(train_X,train_Y,B,lamda,alpha,init_J)\n",
    "        error=cal_MSE_loocv(valid_X,valid_Y,B)\n",
    "        error_list[error]=B.tolist()\n",
    "    return error_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Plot graph between k and error\n",
    "def plot_k_error(df,label,alpha,lamda,total_X,total_Y):\n",
    "    no_coefficients=8\n",
    "    k_list=[]\n",
    "    y_list=[]\n",
    "    list=[3, 5, 9, 10]\n",
    "    for k in list:\n",
    "        print(\"k value \",k)\n",
    "        k_list.append(k)\n",
    "        B = np.zeros(no_coefficients)\n",
    "        folds_list=kfold_cross_val_split(df,k)\n",
    "        error_list = run_cross_val(folds_list,label,alpha,lamda)\n",
    "        B=sort_error(error_list)\n",
    "        error=cal_MSE(total_X,total_Y,B)\n",
    "        print(\"MSE Error \",error)\n",
    "        print()\n",
    "        y_list.append(error)\n",
    "    #Plot Graph\n",
    "    area=np.pi\n",
    "    plt.xlabel(\"k\")\n",
    "    plt.ylabel(\"Error\")\n",
    "\n",
    "    plt.plot(k_list, y_list)\n",
    "    plt.show()\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leave-One-Out Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loocv(df,total_X,total_Y,label,alpha,lamda):\n",
    "    no_coefficients=8 \n",
    "    B = np.zeros(no_coefficients)\n",
    "    error_list = run_loocv(df,label,alpha,lamda)\n",
    "    B=sort_error(error_list)\n",
    "    error=cal_MSE(total_X,total_Y,B)/2\n",
    "    return error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating X(data.T),Y arrays from df\n",
    "def to_arrays(df,label):\n",
    "    no_rows,no_cols=df.shape\n",
    "    header=list(df.columns)\n",
    "    data_array=np.ones((no_cols-1,no_rows))\n",
    "    X0=np.ones(no_rows)                      #X0=1\n",
    "    for i in range(0,no_cols-1):             #Removing first col-serial no , last col-label\n",
    "        if(i == 0):\n",
    "            data_array[i]=X0\n",
    "        else:\n",
    "            x=df[header[i]].values\n",
    "            #data_array[i]=x\n",
    "            data_array[i]=mean_normalize(x)\n",
    "    X=data_array.T        #Doing Transpose\n",
    "\n",
    "    #Y (output) array\n",
    "    Y=np.array(df[label].values)\n",
    "    \n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating X(data.T),Y arrays from df\n",
    "def to_arrays_loocv(df,label):\n",
    "    no_rows,no_cols=df.shape\n",
    "    header=list(df.columns)\n",
    "    data_array=np.ones((no_cols-1,no_rows))\n",
    "    X0=np.ones(no_rows)                      #X0=1\n",
    "    for i in range(0,no_cols-1):             #Removing first col-serial no , last col-label\n",
    "        if(i == 0):\n",
    "            data_array[i]=X0\n",
    "        else:\n",
    "            x=df[header[i]].values\n",
    "            data_array[i]=x\n",
    "            #data_array[i]=mean_normalize(x)\n",
    "    X=data_array.T        #Doing Transpose\n",
    "\n",
    "    #Y (output) array\n",
    "    Y=np.array(df[label].values)\n",
    "    \n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_normalize(x):\n",
    "    x_new=np.ones(len(x))\n",
    "    mean=np.mean(x)\n",
    "    std=np.std(x)\n",
    "    for i in range(0,len(x)):\n",
    "        x_new[i]=(x[i]-mean)/(std)\n",
    "    return x_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_error(error_list):\n",
    "    B=error_list[sorted(error_list)[0]]\n",
    "    return B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    file=\"AdmissionDataset/data.csv\"\n",
    "    label='Chance of Admit '\n",
    "    no_coefficients=8  #[B0,B1,B2,...,B7] also 7 columns but X0=1\n",
    "    \n",
    "    df=pd.read_csv(file)\n",
    "    header=list(df.columns)\n",
    "    \n",
    "    total_X,total_Y=to_arrays(df,label)\n",
    "    \n",
    "    #B(beta) array of coefficients\n",
    "    #Initialized to zero\n",
    "    B = np.zeros(no_coefficients)\n",
    "\n",
    "    alpha = 0.003\n",
    "    lamda = 0.01\n",
    "    k=5\n",
    "        \n",
    "    print(\"Running for k=5\")\n",
    "    folds_list = kfold_cross_val_split(df,k)\n",
    "    error_list = run_cross_val(folds_list,label,alpha,lamda)\n",
    "    B=sort_error(error_list)\n",
    "    print(\"Best parameters choosen for B\")\n",
    "    print(B)\n",
    "\n",
    "    print(\"Testing for Error on entire dataset\")\n",
    "    MSE,MAE,MPE=cal_error(total_X,total_Y,B)\n",
    "    print(\"Mean Square Error-\",MSE)\n",
    "    print(\"Mean Absolute Error-\",MAE)\n",
    "    print(\"Mean Absolute Percentage Error-\",MPE)\n",
    "    \n",
    "    \n",
    "    #Plot between lamda and error\n",
    "    print(\"\\nGraph between k and respective errors\")\n",
    "    plot_k_error(df,label,alpha,lamda,total_X,total_Y)\n",
    "    \n",
    "    #Leave-One-Out Cross Validation\n",
    "    print(\"\\nUsing Leave-One-Out Cross Validation \")\n",
    "    error=loocv(df,total_X,total_Y,label,0.000003,lamda)\n",
    "    print(\"MSE- \",error)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using Leave-One-Out Cross Validation \n",
      "MSE-  0.26950440460315483\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
